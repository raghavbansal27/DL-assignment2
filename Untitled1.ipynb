{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f634a1f4-90ed-4fc6-92e5-72808cf7f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "# import cv2\n",
    "from glob import glob\n",
    "import PIL\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input,decode_predictions\n",
    "from tensorflow.keras.models import Model\n",
    "from mnist.loader import MNIST\n",
    "\n",
    "\n",
    "mndata = MNIST(r'D:\\PycharmProjects\\DLassignment2\\Assignment_Data')\n",
    "X_train, y_train = mndata.load_training()\n",
    "X_test, y_test = mndata.load_testing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "277a0124-9e19-4b80-885e-b81598d4c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08c42955-aeca-4372-9ff5-7ad1ad0dfd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels to numpy array\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test_ = np.array(y_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "688e9e78-a497-4784-9892-1442e036f69d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-16dc11d2752a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    plt.figure()\n",
    "    image = cv2.imread(X_train[i])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d5f245-5b89-4168-b4aa-c69d256c1ae1",
   "metadata": {},
   "source": [
    "# Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2deab6fd-a651-4627-b159-7a16e056fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = {0:['z','e','r','o'], 1: ['o','n','e'], 2:['t','w','o'], 3:['t','h','r','e','e'], 4:['f','o','u','r'], 5:['f','i','v','e'], 6:['s','i','x'], 7:['s','e','v','e','n'], 8:['e','i','g','h','t'], 9:['n','i','n','e']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abcb5687-a09f-4ca3-b71f-be6543ecff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [converter[zi] for zi in y_train]\n",
    "\n",
    "data = dict()\n",
    "for i in range(len(y_train)):\n",
    "    data[str(i)] = y_train[i]\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70092fac-57d1-4537-aaf9-502e16e03104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# convert the following into a vocabulary of words and calculate the total words\n",
    "\n",
    "def vocabulary(data):\n",
    "    all_desc = set()\n",
    "    for key in data.keys():\n",
    "        [all_desc.update(d.split()) for d in data[key]]\n",
    "    return all_desc\n",
    "\n",
    "# summarize vocabulary\n",
    "vocabulary_data = vocabulary(data)\n",
    "print(len(vocabulary_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3594144c-7c1d-4834-adc9-18bd792dba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e', 'f', 'g', 'h', 'i', 'n', 'o', 'r', 's', 't', 'u', 'v', 'w', 'x', 'z'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "258cc47b-02b1-4642-9d1e-1514f8709cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save descriptions to file, one per line\n",
    "\n",
    "def save_dict(data, filename):\n",
    "    lines = list()\n",
    "    for key, value in data.items():\n",
    "        for desc in value:\n",
    "            lines.append(key + ' ' + desc)\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "\n",
    "save_dict(data, 'captions.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bffdbb-7484-4414-97ab-05c92d0ca6bc",
   "metadata": {},
   "source": [
    "# Preprocessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34ff8dcd-983f-48ec-9e28-ab43aacedd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    img = image    \n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "    # plt.imshow(img[0], cmap='gray')\n",
    "    # plt.show()\n",
    "    # print(img.shape)\n",
    "    img = tf.image.resize_with_pad(img, 224, 224)\n",
    "    # print(img.shape)\n",
    "    img = img.reshape(1, 224, 224)\n",
    "    # print(img.shape)\n",
    "    img = np.repeat(img[..., np.newaxis], 3, -1)\n",
    "    # print(img.shape)\n",
    "    # plt.imshow(img[0], cmap='gray')\n",
    "    # plt.show()\n",
    "    image = preprocess_input(img)\n",
    "    # pred = model.predict(image)\n",
    "    \n",
    "    return image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea3148ef-a018-4927-8f71-288464d351ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ResNet50 model\n",
    "model = ResNet50()\n",
    "# restructure the model\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "# summarize\n",
    "# print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0bd843-70e9-43b9-9002-81e6eabf3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a given image into a vector of size (2048, )\n",
    "def encode(image):\n",
    "    image = preprocess(image) # preprocess the image\n",
    "    fea_vec = model.predict(image) # Get the encoding vector for the image\n",
    "    fea_vec = np.reshape(fea_vec, fea_vec.shape[1]) # reshape from (1, 2048) to (2048, )\n",
    "    return fea_vec\n",
    "    \n",
    "encoding = {}\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    encoding[i] = encode(X_train[i])\n",
    "    \n",
    "import pickle\n",
    "\n",
    "# Save the features in the images1 pickle file\n",
    "with open(\"images1.pkl\", \"wb\") as encoded_pickle:\n",
    "    pickle.dump(encoding, encoded_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999af93-03ab-4d77-b39c-8dcd6a9f2013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
